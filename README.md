# Deep Image-to-Video Adaptation and Fusion Networks for Action Recognition

<a href="https://orcid.org/0000-0002-9423-9252" target="orcid.widget" rel="noopener noreferrer" style="vertical-align:top;"><img src="https://orcid.org/sites/default/files/images/orcid_16x16.png" style="width:1em;margin-right:.5em;" alt="ORCID iD icon">orcid.org/0000-0002-9423-9252</a>

Homepage: [https://sites.google.com/site/yangliuxdu/home](https://sites.google.com/site/yangliuxdu/home)

## Network architecture
![Image](Network_image.png)

Figure 1: Configuration of the deep neural network for image modality. "f" denotes the number of convolutional filters and
their receptive field size, "st" denotes the convolutional stride, "pad" denotes the number of pixels to add to each size of the
input, "LRN" denotes whether Local Response Normalization (LRN) is applied or not, and “pool” denotes the downsampling factor.

![Image](Network_video.png)

Figure 2: Configuration of the deep neural network for video modality

## Algorithm

![Image](ALgorithm.png)

## Datasets

### Stanford40->UCF101 dataset can be downloaded [here](http://4drepository.inrialpes.fr/public/viewgroup/6#sequence37).

### ASD->UCF101 dataset can be downloaded [here](http://users.eecs.northwestern.edu/~jwa368/my_data.html).

### EAD->HMDB51 dataset can be downloaded [here](http://csee.wvu.edu/~vkkulathumani/wvu-action.html).

### BU101->UCF101 dataset can be downloaded [here](http://dipersec.king.ac.uk/MuHAVi-MAS/).


## Codes
Soon will be available.
